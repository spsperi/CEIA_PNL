{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "# Procesamiento de lenguaje natural\n",
        "## Desafio 3: Modelo de lenguaje con tokenización por caracteres\n",
        "\n",
        "Alumno: Sofia Speri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Voy a utilizar dataset sobre FAQ's medical question-answer pairs created from 12 NIH websites (e.g. cancer.gov, niddk.nih.gov, GARD, MedlinePlus Health Topics). Fuente: https://www.kaggle.com/datasets/jpmiller/layoutlm\n",
        "\n",
        "Del dataset tomé un grupo de preguntas y respuestas y las junté en un sólo archivo con formato txt para este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/cancer_faqs.txt', sep='/n', header=None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "vL61Oj3EDZG0",
        "outputId": "039381c7-effb-49c3-d672-1ae617aa6e71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-091af6ed99d1>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  df = pd.read_csv('/content/cancer_faqs.txt', sep='/n', header=None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0         What is are Adult Acute Myeloid Leukemia ?\n",
              "1  - Adult acute myeloid leukemia (AML) is a type...\n",
              "2  Who is at risk for Adult Acute Myeloid Leukemi...\n",
              "3  Smoking, previous chemotherapy treatment, and ...\n",
              "4  What are the symptoms of Adult Acute Myeloid L..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6c160a8-2a62-4189-bc9b-2f7cd7dc5a95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is are Adult Acute Myeloid Leukemia ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>- Adult acute myeloid leukemia (AML) is a type...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who is at risk for Adult Acute Myeloid Leukemi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Smoking, previous chemotherapy treatment, and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the symptoms of Adult Acute Myeloid L...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6c160a8-2a62-4189-bc9b-2f7cd7dc5a95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6c160a8-2a62-4189-bc9b-2f7cd7dc5a95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6c160a8-2a62-4189-bc9b-2f7cd7dc5a95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dbcbcd2f-420e-480d-b33f-0893af7c09ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dbcbcd2f-420e-480d-b33f-0893af7c09ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dbcbcd2f-420e-480d-b33f-0893af7c09ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 484,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 460,\n        \"samples\": [\n          \"- The results of diagnostic and staging tests are used to find out if cancer cells have spread. - There are three ways that cancer spreads in the body. - Cancer may spread from where it began to other parts of the body. - Stages are used to describe the different types of bile duct cancer. - Intrahepatic bile duct cancer - Perihilar bile duct cancer - Distal extrahepatic bile duct cancer - The following groups are used to plan treatment: - Resectable (localized) bile duct cancer - Unresectable, metastatic, or recurrent bile duct cancer The results of diagnostic and staging tests are used to find out if cancer cells have spread. The process used to find out if cancer has spread to other parts of the body is called staging. For bile duct cancer, the information gathered from tests and procedures is used to plan treatment, including whether the tumor can be removed by surgery. There are three ways that cancer spreads in the body. Cancer can spread through tissue, the lymph system, and the blood: - Tissue. The cancer spreads from where it began by growing into nearby areas. - Lymph system. The cancer spreads from where it began by getting into the lymph system. The cancer travels through the lymph vessels to other parts of the body. - Blood. The cancer spreads from where it began by getting into the blood. The cancer travels through the blood vessels to other parts of the body. Cancer may spread from where it began to other parts of the body. When cancer spreads to another part of the body, it is called metastasis. Cancer cells break away from where they began (the primary tumor) and travel through the lymph system or blood. - Lymph system. The cancer gets into the lymph system, travels through the lymph vessels, and forms a tumor (metastatic tumor) in another part of the body. - Blood. The cancer gets into the blood, travels through the blood vessels, and forms a tumor (metastatic tumor) in another part of the body. The metastatic tumor is the same type of cancer as the primary tumor. For example, if bile duct cancer spreads to the liver, the cancer cells in the liver are actually bile duct cancer cells. The disease is metastatic bile duct cancer, not liver cancer. Stages are used to describe the different types of bile duct cancer. Intrahepatic bile duct cancer - Stage 0: Abnormal cells are found in the innermost layer of tissue lining the intrahepatic bile duct. These abnormal cells may become cancer and spread into nearby normal tissue. Stage 0 is also called carcinoma in situ. - Stage I: There is one tumor that has spread into the intrahepatic bile duct and it has not spread into any blood vessels. - Stage II: There is one tumor that has spread through the wall of the bile duct and into a blood vessel, or there are multiple tumors that may have spread into a blood vessel. - Stage III: The tumor has spread through the tissue that lines the abdominal wall or has spread to organs or tissues near the liver such as the duodenum, colon, and stomach. - Stage IV: Stage IV is divided into stage IVA and stage IVB. - Stage IVA: The cancer has spread along the outside of the intrahepatic bile ducts or the cancer has spread to nearby lymph nodes. - Stage IVB: The cancer has spread to organs in other parts of the body. Perihilar bile duct cancer - Stage 0: Abnormal cells are found in the innermost layer of tissue lining the perihilar bile duct. These abnormal cells may become cancer and spread into nearby normal tissue. Stage 0 is also called carcinoma in situ. - Stage I: Cancer has formed in the innermost layer of the wall of the perihilar bile duct and has spread into the muscle layer or fibrous tissue layer of the wall. - Stage II: Cancer has spread through the wall of the perihilar bile duct to nearby fatty tissue or to the liver. - Stage III: Stage III is divided into stage IIIA and stage IIIB. - Stage IIIA: Cancer has spread to branches on one side of the hepatic artery or of the portal vein. - Stage IIIB: Cancer has spread to nearby lymph nodes. Cancer may have spread into the wall of the perihilar bile duct or through the wall to nearby fatty tissue, the liver, or to branches on one side of the hepatic artery or of the portal vein. - Stage IV: Stage IV is divided into stage IVA and stage IVB. - Stage IVA: Cancer has spread to one or more of the following: - the main part of the portal vein and/or common hepatic artery; - the branches of the portal vein and/or common hepatic artery on both sides; - the right hepatic duct and the left branch of the hepatic artery or of the portal vein; - the left hepatic duct and the right branch of the hepatic artery or of the portal vein. Cancer may have spread to nearby lymph nodes. - Stage IVB: Cancer has spread to lymph nodes in more distant parts of the abdomen, or to organs in other parts of the body. Distal extrahepatic bile duct cancer - Stage 0: Abnormal cells are found in the innermost layer of tissue lining the distal extrahepatic bile duct. These abnormal cells may become cancer and spread into nearby normal tissue. Stage 0 is also called carcinoma in situ. - Stage I: Stage I is divided into stage IA and stage IB. - Stage IA: Cancer has formed and is found in the distal extrahepatic bile duct wall only. - Stage IB: Cancer has formed and has spread through the wall of the distal extrahepatic bile duct but has not spread to nearby organs. - Stage II: Stage II is divided into stage IIA and stage IIB. - Stage IIA: Cancer has spread from the distal extrahepatic bile duct to the gallbladder, pancreas, duodenum, or other nearby organs. - Stage IIB: Cancer has spread from the distal extrahepatic bile duct to nearby lymph nodes. Cancer may have spread through the wall of the duct or to nearby organs. - Stage III: Cancer has spread to the large vessels that carry blood to the organs in the abdomen. Cancer may have spread to nearby lymph nodes. - Stage IV: Cancer has spread to organs in distant parts of the body. The following groups are used to plan treatment: Resectable (localized) bile duct cancer The cancer is in an area, such as the lower part of the common bile duct or perihilar area, where it can be removed completely by surgery. Unresectable, metastatic, or recurrent bile duct cancer Unresectable cancer cannot be removed completely by surgery. Most patients with bile duct cancer cannot have their cancer completely removed by surgery. Metastasis is the spread of cancer from the primary site (place where it started) to other places in the body. Metastatic bile duct cancer may have spread to the liver, other parts of the abdominal cavity, or to distant parts of the body. Recurrent bile duct cancer is cancer that has recurred (come back) after it has been treated. The cancer may come back in the bile ducts, liver, or gallbladder. Less often, it may come back in distant parts of the body.\",\n          \"What is are Adult Soft Tissue Sarcoma ?\",\n          \"Cancer prevention clinical trials are used to study ways to prevent cancer. Cancer prevention clinical trials are used to study ways to lower the risk of developing certain types of cancer. Some cancer prevention trials are conducted with healthy people who have not had cancer but who have an increased risk for cancer. Other prevention trials are conducted with people who have had cancer and are trying to prevent another cancer of the same type or to lower their chance of developing a new type of cancer. Other trials are done with healthy volunteers who are not known to have any risk factors for cancer. The purpose of some cancer prevention clinical trials is to find out whether actions people take can prevent cancer. These may include exercising more or quitting smoking or taking certain medicines, vitamins, minerals, or food supplements. New ways to prevent breast cancer are being studied in clinical trials.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = list(df.loc[:,0])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JAqrqTVdFGEC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "#Lista de párrafos\n",
        "article_text = ''\n",
        "\n",
        "for para in text:\n",
        "   article_text += para + ' '\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len(article_text)"
      ],
      "metadata": {
        "id": "g3mf_jifvUgj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WBE0sSYuB-E6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3070665b-ddc8-47a3-d96a-20238bcf5301"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Acoto el texto a los primeros 100000\n",
        "article_text = article_text[:100000]\n",
        "len(article_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "573Cg5n7VhWw",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VwTK6xgLJd8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6668e469-6b4b-4580-8e90-103d67c7548f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WSSmg9jtKP0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8c4ed2-9084-4d07-9d62-022cc92c9073"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))\n",
        "num_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KFAyA4zCWE-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0bc8dc-0d69-4b41-8de2-8ae0e40767a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89800, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qcKRl70HFTzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b25237-1d41-4b6c-97df-3064dfd70fef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([42, 14, 11, 39, 33,  9,  0, 33, 11, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TVpLCKSZFXZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1bbb4a-a6d8-4953-f677-eada9b19872a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14, 11, 39, 33,  9,  0, 33, 11, 16,  6])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wOFCR-KqbW1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3726a7e7-b113-4a62-bcb8-25ae3dea412e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Zd2OkfQYs2Q7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "7ae23c71-437f-4445-cbcd-20df5ed85067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │          \u001b[38;5;34m14,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)            │           \u001b[38;5;34m4,545\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,145\u001b[0m (74.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,145</span> (74.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,145\u001b[0m (74.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,145</span> (74.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model_char.h5\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oQq1PHDkxDvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e335034-2086-4c79-f1c1-b1423c49dbd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 2.9215"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 10.133767819206662 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 524ms/step - loss: 2.9201\n",
            "Epoch 2/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - loss: 2.2248"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 8.305690025611396 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 486ms/step - loss: 2.2245\n",
            "Epoch 3/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 2.0136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 7.2883923855465795 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 487ms/step - loss: 2.0134\n",
            "Epoch 4/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - loss: 1.8872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 6.725214341238028 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 492ms/step - loss: 1.8871\n",
            "Epoch 5/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 1.7907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 6.223968788473544 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 488ms/step - loss: 1.7905\n",
            "Epoch 6/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - loss: 1.7136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 5.778477647984462 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 498ms/step - loss: 1.7135\n",
            "Epoch 7/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 1.6568"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 5.455973923932617 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 497ms/step - loss: 1.6568\n",
            "Epoch 8/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - loss: 1.6139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 5.091603005675456 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 485ms/step - loss: 1.6139\n",
            "Epoch 9/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - loss: 1.5773"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 4.927968367745844 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 497ms/step - loss: 1.5772\n",
            "Epoch 10/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - loss: 1.5481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " mean perplexity: 4.798147445364559 \n",
            "\n",
            "Saved new model!\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 505ms/step - loss: 1.5481\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=10, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "K30JHB3Dv-mx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "45ce838e-2616-43e8-8bb1-fa9e3f0359c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.ylabel(\"Perplexity\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rhy5hZN38qfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a12d68-7f20-43b4-da0f-bf7e8437e241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model_char.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HNyBykvhzs7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "outputId": "dc3ff493-bdef-42b9-b1ed-4ead8b88089e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://8a0fa1ead62aab2081.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8a0fa1ead62aab2081.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8a0fa1ead62aab2081.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08ca818e-f657-4134-8eea-28bb5db3c3b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is the body to the body to the body '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "input_text='what is the'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"the cancer is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "P8HQoLhw-NYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ad97a5-31cf-4efc-8209-82ba9516d81e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([39, 14,  6, 33, 23, 11, 21, 23,  6, 16, 33,  9,  0, 33, 11, 33, 23,\n",
              "       41,  9, 21,  9, 23, 11, 41, 33, 39, 16,  9, 11, 41,  0, 33, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2S3_I3S1W1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d020d9df-db6c-4ddb-9dd3-96c45cc4cd9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the cancer is a clinical trials t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": [
        "## Observaciones\n",
        "\n",
        "EL modelo entrenado está pudiendo interpretar y predecir con <sentido> los caracteres, ya que como se ve en las imágenes, logra completar las plabras y poner espacios donde correpsonde; a pesar, de ser entrenado con el corpus acotado por recursos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}